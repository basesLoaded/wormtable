#!python
"""
VCF processing for wormtable. 

TODO:document.

Implementation Note: We use bytes throughout the parsing process here for
a few reasons. Mostly, this is because it's much easier to deal with bytes
values within the C module, as we'd have to decode Unicode objects before 
getting string. At the same time, it's probably quite a bit more efficient 
to work with bytes directly, so we win both ways. It's a bit tedious making 
sure that all the literals have a 'b' in front of them, but worth the 
effort.

"""
from __future__ import print_function
from __future__ import division 

import os
import sys
import optparse
import shutil 
import gzip

import wormtable as wt
import _wormtable

# VCF Fixed columns

CHROM = b"CHROM"
POS = b"POS"
ID = b"ID"
REF = b"REF"
ALT = b"ALT"
QUAL = b"QUAL"
FILTER = b"FILTER"
INFO = b"INFO"

# Special values in VCF
MISSING_VALUE = b"."

# Strings used in the header for identifiers
ID = b"ID"
DESCRIPTION = b"Description"
NUMBER = b"Number"
TYPE = b"Type"
INTEGER = b"Integer"
FLOAT = b"Float"
FLAG = b"Flag"
CHARACTER = b"Character"
STRING = b"String"

def vcf_column_factory(line):
    """
    Returns a column object suitable for encoding a vcf column described by the 
    specified meta-information line.
    """
    d = {}
    s = line[line.find(b"<") + 1: line.find(b">")]
    for j in range(3):
        k = s.find(b",")
        tokens = s[:k].split(b"=")
        s = s[k + 1:]
        d[tokens[0]] = tokens[1]
    tokens = s.split(b"=", 1)
    d[tokens[0]] = tokens[1]
    name = d[ID]
    description = d[DESCRIPTION].strip(b"\"")
    number = d[NUMBER]
    num_elements = wt.WT_VARIABLE 
    try:
        # If we can parse it into a number, do so. If this fails than use
        # a variable number of elements.
        num_elements = int(number)    
    except ValueError as v:
        pass
    # We can also have negative num_elements to indicate variable column
    if num_elements < 0:
        num_elements = wt.WT_VARIABLE 
    st = d[TYPE]
    if st == INTEGER:
        element_type = wt.WT_INT
        element_size = 4
    elif st == FLOAT: 
        element_type = wt.WT_FLOAT
        element_size = 4
    elif st == FLAG: 
        element_type = wt.WT_INT
        element_size = 1
    elif st == CHARACTER: 
        element_type = wt.WT_CHAR
        element_size = 1
    elif st == STRING: 
        num_elements = wt.WT_VARIABLE 
        element_type = wt.WT_CHAR
        element_size = 1
    else:
        raise ValueError("Unknown VCF type:", st)
    col = _wormtable.Column(name, description, element_type, 
            element_size, num_elements)
    return col
   
def copy_column(col, prefix):
    """
    Returns a copy of the specified column with the specified prefix 
    appended to its name.
    """
    new_name = prefix + b"_" + col.name
    new_col = _wormtable.Column(name=new_name, description=col.description, 
            element_type=col.element_type, element_size=col.element_size, 
            num_elements=col.num_elements)
    return new_col

class VCFSchemaGenerator(object):
    """
    Class that generates a database schema for a VCF file by parsing 
    the header.
    """
    def __init__(self, vcf_file):
        self._file = vcf_file
        self._info_columns = [] 
        self._genotype_columns = []
    
    def _parse_version(self, s):
        """
        Parse the VCF version number from the specified string.
        """
        self._version = -1.0
        tokens = s.split(b"v")
        if len(tokens) == 2:
            self._version = float(tokens[1])

    def _parse_meta_information(self, line):
        """
        Processes the specified meta information line to obtain the values 
        of the various columns and their types.
        """
        if line.startswith(b"##INFO"):
            col = vcf_column_factory(line)
            self._info_columns.append(col)
        elif line.startswith(b"##FORMAT"):
            col = vcf_column_factory(line)
            self._genotype_columns.append(col)
        else:
            pass
            # Should we parse the FILTER values and make a proper enum 
            # column? Probably.

    def _parse_header_line(self, s):
        """
        Processes the specified header string to get the genotype labels.
        """
        self._genotypes = s.split()[9:]

    def generate_schema(self):
        """
        Reads the header for this VCF file, constructing the database 
        schema and returning it. 
        """
        f = self._file 
        s = f.readline()
        self._parse_version(s)
        if self._version < 4.0:
            raise ValueError("VCF versions < 4.0 not supported")
        while s.startswith(b"##"):
            self._parse_meta_information(s)
            s = f.readline()
        self._parse_header_line(s)
        int_type = wt.WT_INT
        char_type = wt.WT_CHAR
        float_type = wt.WT_FLOAT
        #enum_type = _wormtable.ELEMENT_TYPE_ENUM
        # TMP while we're fixing enums
        enum_type = wt.WT_CHAR
        variable = wt.WT_VARIABLE
        # Get the fixed columns
        # TODO Add string constants at the top of the file for the descriptions 
        # of these columns.
        columns = [
            _wormtable.Column(b"row_id", b"Row position", wt.WT_UINT, 5, 1),
            _wormtable.Column(CHROM, b"Chromosome", enum_type, 1, variable),
            _wormtable.Column(POS, b"position", int_type, 5, 1),
            _wormtable.Column(ID, b"ID", char_type, 1, variable),  
            _wormtable.Column(REF, b"Reference allele", enum_type, 1, variable),
            _wormtable.Column(ALT, b"Alternatve allele", enum_type, 1, variable),
            _wormtable.Column(QUAL, b"Quality", float_type, 4, 1),
            _wormtable.Column(FILTER, b"Filter", char_type, 1, variable),
        ]
        for col in self._info_columns:
            columns.append(copy_column(col, INFO))
        for genotype in self._genotypes:
            for col in self._genotype_columns:
                columns.append(copy_column(col, genotype))
        schema = wt.Schema(columns)
        return schema

def vcf_schema_factory(vcf_file):
    """
    Returns a schema for the specified VCF file.
    """
    reading_file, progress_file = open_file(vcf_file)
    sg = VCFSchemaGenerator(reading_file)
    schema = sg.generate_schema()
    reading_file.close()
    return schema

def open_file(vcf_file):
    """
    Opens the specified VCF file and returns two file objects: one ready 
    for reading, and the other indicating the position in the underlying 
    file. If compression is not used, these are the same. Only the 
    reading_file should be closed at the end of the process.
    """
    if vcf_file.endswith(".gz"):
        reading_file = gzip.open(vcf_file, "rb")
        progress_file = reading_file.fileobj
    else:
        reading_file = open(vcf_file, "rb")
        progress_file = reading_file
    return reading_file, progress_file


class VCFTableBuilder(wt.TableBuilder):
    """
    Class responsible for parsing a VCF file and creating a database. 
    """
  
    def set_progress_monitoring(self, monitor):
        """
        If monitor is true turn on progress monitoring; otherwise, turn it off.
        """

    def set_progress_update_rows(self, progress_update_rows):
        """
        Sets the number of rows that we update progress at to the specified 
        value.
        """
        self._progress_update_rows = progress_update_rows

    def _update_progress(self):
        """
        Reads the position we are at in the underlying file and uses this to 
        update the progress bar, if used.
        """
        if self._progress_monitor is not None:
            t = self._progress_file.tell() 
            self._progress_monitor.update(t)

    def build(self, vcf_file, progress_monitor=False):
        """
        Builds the table.
        """
        self._progress_monitor = None
        reading_file, progress_file = open_file(vcf_file)
        file_size = os.path.getsize(vcf_file) 
        if progress_monitor:
            self._progress_monitor = wt.ProgressMonitor(file_size, "bytes")
        self._source_file = reading_file 
        self._progress_file = progress_file
        self.open_database()
        self._prepare()
        self._insert_rows()
        self.close_database()
        self.finalise()
        reading_file.close()
        if progress_monitor:
            self._progress_monitor.update(file_size)
            self._progress_monitor.finish()

   
    def _prepare(self):
        """
        Prepares for parsing records by getting the database columns 
        ready and skipping the file header.
        """
        f = self._source_file
        # Skip the header
        s = f.readline()
        while s.startswith(b"##"):
            s = f.readline()
        # Get the genotypes from the header
        genotypes = s.split()[9:] 
        # In the interest of efficiency, we want to split the columns 
        # up into the smallest possible lists so we don't have to 
        # put in as much effort searching for them.
        all_columns = dict((c.name, c) for c in self._schema.get_columns())
        all_fixed_columns = [CHROM, POS, ID, REF, ALT, QUAL, FILTER]
        self._fixed_columns = []
        for j in range(len(all_fixed_columns)):
            name = all_fixed_columns[j]
            if name in all_columns:
                self._fixed_columns.append((all_columns[name], j))
        self._info_columns = {}
        self._genotype_columns = [{} for g in genotypes]
        for c in self._schema.get_columns()[1:]:
            if b"_" in c.name:
                split = c.name.split(b"_")
                if split[0] == INFO:
                    name = split[1]
                    self._info_columns[name] = c
                else:
                    g = b"_".join(split[:-1])
                    name = split[-1]
                    index = genotypes.index(g)
                    self._genotype_columns[index][name] = c
    

    def _insert_elements(self, col, encoded):
        """
        Insert the elements into the table after converting to the correct
        types.
        
        This should be redundant if we're using the C based parsing of encoded
        elements.
        """
        col_position = col.position 
        rb = self._row_buffer
        if col.element_type == wt.WT_CHAR:
            rb.insert_elements(col_position, encoded)
        else:
            f = int
            if col.element_type == wt.WT_FLOAT:
                f = float
            if col.num_elements == 1:
                rb.insert_elements(col_position, f(encoded))
            else:
                l = [f(s) for s in encoded.split(b",")]
                rb.insert_elements(col_position, l)
                    
                

    def _insert_rows(self):
        """
        Builds the database in opened file.
        """
        fixed_columns = self._fixed_columns
        info_columns = self._info_columns
        genotype_columns = self._genotype_columns
        t = self._row_buffer
        num_rows = 0
        for s in self._source_file:
            l = s.split()
            # Read in the fixed columns
            for col, index in fixed_columns:
                if l[index] != MISSING_VALUE:
                    t.insert_encoded_elements(col.position, l[index])
                    #self._insert_elements(col, l[index])
            # Now process the info columns.
            for mapping in l[7].split(b";"):
                tokens = mapping.split(b"=")
                name = tokens[0]
                if name in info_columns:
                    col = info_columns[name]
                    if len(tokens) == 2:
                        t.insert_encoded_elements(col.position, tokens[1])
                        #self._insert_elements(col, tokens[1])
                    else:
                        # This is a Flag column.
                        t.insert_elements(col.position, [1])
            # Process the genotype columns. 
            j = 0
            fmt = l[8].split(b":")
            for genotype_values in l[9:]:
                tokens = genotype_values.split(b":")
                if len(tokens) == len(fmt):
                    for k in range(len(fmt)):
                        if fmt[k] in genotype_columns[j]:
                            col = genotype_columns[j][fmt[k]]
                            t.insert_encoded_elements(col.position, tokens[k])
                            #self._insert_elements(col, tokens[k])
                elif len(tokens) > 1:
                    # We can treat a genotype value on its own as missing values.
                    # We can have skipped columns at the end though, which we 
                    # should deal with properly. So, put in a loud complaint 
                    # here and fix later.
                    print("PARSING CORNER CASE NOT HANDLED!!! FIXME!!!!")
                j += 1
            # Finally, commit the record.
            self._row_buffer.commit_row()
            num_rows += 1
            if num_rows % self._progress_update_rows == 0:
                self._update_progress()

####### Command line interface ###############

def main():
    usage = "usage: %prog [options] vcf-file homedir"
    parser = optparse.OptionParser(usage=usage) 
    parser.add_option("-f", "--force", dest="force",
            action="store_true", default=False,
            help="overwrite existing wormtable", metavar="FORCE")
    parser.add_option("-p", "--progress", dest="progress",
            action="store_true", default=False,
            help="show progress monitor", metavar="PROGRESS")
    parser.add_option("-c", "--cache-size", dest="cache_size",
            help="cache size in K, M or G", default="64M")
    (options, args) = parser.parse_args()
    if len(args) != 2:
        parser.error("Incorrect number of arguments")

    cache_size = wt.parse_cache_size(options.cache_size)
    vcf_file = args[0]
    homedir = args[1]
    if os.path.exists(homedir):
        if options.force:
            shutil.rmtree(homedir)
        else:
            s = "Directory '{0}' exists: use -f to overwrite".format(homedir)
            parser.error(s)
    os.mkdir(homedir)
    
    input_schema = os.path.join(homedir, "schema.xml")
    schema = vcf_schema_factory(vcf_file)
    schema.write_xml(input_schema)
    dbb = VCFTableBuilder(homedir, input_schema)
    dbb.set_cache_size(cache_size)
    # we want fluid progress for small files and to not
    # waste time for large files.
    progress_rows = 100
    statinfo = os.stat(vcf_file)
    if statinfo.st_size > 2**30:
        progress_rows = 10000
    dbb.set_progress_update_rows(progress_rows)
    dbb.build(vcf_file, options.progress)
    

if __name__ == "__main__":
    main()

