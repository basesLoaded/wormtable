\documentclass{bioinfo}

% Bioinformatics definitions.

\copyrightyear{2013}
\pubyear{2013}

\begin{document}
\firstpage{1}

\title[Wormtable]{Wormtable: A data structure for genome scale data}
\author[Kelleher \textit{et~al}]{Jerome Kelleher, Robert W. Ness 
and Daniel L. Halligan}
\address{
University of Edinburgh,
King's Buildings,
West Mains Road,
EH9 3JT,
UK
}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\maketitle

\begin{abstract}
\section{Summary:}
Biological research generates vast quantities of tabular data, which must 
be processed to test hypotheses. These tables are produced by 
programs and exported to plain text files, which are often very large. 
Researchers must process these files 
line-by-line, parsing values encoded as text into native types so that 
calculations may be done. This is an extremely inefficient process.
Furthermore, there is no simple means of indexing these files so that 
arbitrary data values within rows can be quickly found. We introduce a new 
data format and software library called wormtable, which provides efficient 
access to tabular data in Python. Wormtable stores data in a compact
binary format, provides random access to rows, and enables sophisticated
indexing on columns within these tables.
\section{Availability:}
Package available at 
\href{http://pypi.python.org/pypi/wormtable}{http://pypi.python.org/pypi/wormtable}

\section{Contact:} \href{jerome.kelleher@ed.ac.uk}{jerome.kelleher@ed.ac.uk}
\end{abstract}

\section{Introduction}
% Lots of data
The improvement in sequencing technologies has
lead to an exponential increase in the volume of data being managed 
by biologists. Standard studies require the storage and processing 
of hundreds of gigabytes of data, and this volume of data is only set to 
increase as sequencing technologies continue to improve.

% but we use text files
Despite the increasing importance of data processing, however, the methods 
used in Bioinformatics are almost entirely 
based around the use of text files. Plain text files have many advantages:
they are extremely portable and can be processed on 
any platform with the minimum of library dependencies. Text files also 
have many disadvantages however; the principle difficulties for our 
purposes here are, they are slow to parse and difficult to index.

% text files are also easy to read/comprehend and don't require specialist
% knowledge to process.
% I think learning a database syntax is a barrier to many researchers that are
% not trained bioinformaticians

% Databases solve these problems
The classical approach to working with large volumes of 
structured data is to use a database, which solve these 
problems very effectively.
Data is typically encoded in an efficient binary 
format, saving substantial space and avoiding the need
for repeated parsing. Records are usually stored in a
B-tree, leading to fast access times even 
over very large datasets. Indexing over columns within rows is 
also very powerful, allowing us to quickly retrieve 
rows with particular features. 

% Databases but introduce several others. 
One may, of course, load textual data into a relational database, and 
use SQL to retrieve the records of interest. This approach has several 
disadvantages, however. Firstly, one must first examine the data 
and construct an appropriate SQL schema to define the appropriate columns. 
It is sometimes feasible to do this automatically 
for data files, but is certainly not a trivial process, 
particularly if the schema 
must be portable across different relational database platforms.
Even assuming that the data 
has been inserted into a table with an appropriate schema, there 
are still difficulties to be addressed. Maintaining a database 
server is a difficult task and when the volumes of data become
large, a specialised administrator is usually required to 
ensure the server works correctly.

% We don't need concurrency, etc, as it's always read-only.
Much of the time, a database server is far more complicated than
we require for biological data. Data files 
are usually written once by an application 
and do not subsequently change. Thus, storing this information 
in a relational database with its sophisticated concurrency control
and guarantees of consistency in the face of asynchronous updates
is entirely unnecessary. Interacting with a database is also a
substantial hurdle, as another lanuage must be learned in order 
to gain access to data. Relational databases, although providing 
powerful data management technologies are far more complex than 
is required, and are therefore little used for the types of 
data that we are interested in.

\section{Wormtable}
% what is wormtable?
Wormtable (write-once read-many table) 
is a new data format and software library designed specifically
to deal with the challenges of data processing in bioinformatics.
It provides a portable, compact, read-only store for tabular
data of essentially unlimited size. Tables can
be either written directly via the library, or converted
from existing formats via command line tools. Tables can be read 
concurrently by any number of processes, and are accessed by a 
simple API in Python.

% why do we use Berkeley DB?
To take advantage of the data processing capabilities of database
technologies without the overheads and disadvantages of a relational database 
server, wormtable uses Berkeley DB~\citep{obs99} for row storage and indexing.
Berkeley DB is an open source embedded database toolkit, that provides a
scalable key-value store~\citep{m12}. It is a mature and stable platform, 
and is currently the most widely deployed database toolkit in the 
world~\citep{sb12}. DB is a highly modular library, providing the 
means to define a very lightweight read-only database, without the 
overheads of a server process

% Wormtable's binary row format 
On this solid foundation of row storage in Berkeley DB, wormtable uses a
compact binary row format designed specifically for biological applications.
Each row contains data from a fixed number of columns, and each column 
holds either a fixed or variable number of elements of a fixed type and size.
Supported types are signed and unsigned integers, 
floating point and character data. To ensure that values are 
stored as compactly as possible, wormtable supports integer values from 
$1$ to $8$ bytes, and the standard single and double precision 
floating point values. 

% Wormtable's indexes 
An essential element of database technology is the ability to index tables
to rows with certain properties to be quickly retrieved. Wormtable 
supports indexing over columns or groups of columns within a table, 
making many operations extremely efficient. 

\section{Examples}

% What is VCF?
A popular file format for Bioinformatics use is the Variant Call Format~\citep{da+11},
or VCF. In VCF,  information about variant sites in a genome is encoded 
as tab-delimited rows in a text file. To access information about a 
particular site, one must proceed through the file line-by-line until the 
desired record is found. There are methods available to index this 
file~\citep{li11}, but these have no semantic 
understanding of the structure of the file and so are limited in the 
fields that can be indexed. One cannot, for example, build an index 
to quickly obtain all records in which the quality field is greater
than some value. Such queries can take a considerable time on large VCF 
files, which discourages testing and checking for the effects of 
arbitrary thresholds in analyses.

Wormtable is designed to make working with genome scale data more 
efficient, and in this section we describe some examples to 
illustrate the improvements over existing methods. To do this, 
we converted a VCF file with XXX rows from the YYY project 
into wormtable format using the included \texttt{vcf2wt} 
conversion program.  The (uncompressed) VCF file was XX
gigabytes, and the converted wormtable YY gigabytes, which required 
X hours.

Values are stored in wormtable in a binary format, so that no parsing is
required when reading in rows. Methods using the VCF directly must parse 
each row before it can be used, and this parsing is by far the most time 
consuming part of processing VCF data. To illustrate this advantage, we
wrote a script to count the number of transitions and transversions
in the dataset, using wormtable and using PyVCF[citation?]. Both of these
methods proceeded row-by-row, checking the ALT and REF columns. The 
PyVCF method required X hours to complete, while the wormtable 
based script needed only Y seconds. This stark difference is not a 
criticism of the PyVCF library, which provides an efficient parser 
for VCF files; it is rather a measure of the inherent slowness of
parsing text in large volumes.

It is well known, of course, that plain text cannot be retrieved 
efficiently at large scales. The BVCF format is an binary version 
of VCF which is intended to avoid this overhead [citation?]. 
This binary format does alleviate the problem of parsing overhead,
but does not solve the problem of indexing \emph{within} rows.

To illustrate the use of indexes in wormtable, 
we created an index on the ALT and REF columns, 
This index required X MB of disc space Y minutes to build, respectively. 
The ALT+REF index provides a much more efficient means of counting 
the transitions and transversions, and another script to calculate 
these required x seconds. 

The examples in this section are intended to illustrate the 
magnitude of performance gains that wormtable can provide 
when working with large datasets. The gains are many: we 
do not have to parse the information before it is used;
we can quickly seek to arbitrary rows within a table; and 
we can use indexes to intelligently sort and aggregate our
data to make it more useful.

\section{Conclusions}
% text files are good for archiving, but terrible for processing
Text files are the oldest and most reliable means of exchanging 
information between computers. Plain text, however, does not provide an efficient 
means of storing and processing large volumes of data. Current practice 
in bioinformatics is to encode data in more and more complex plain 
text data formats. While these formats are excellent from the perspective 
of minimising software dependencies, they are very inefficient in terms of 
storage space, the time required to parse them, and the linear
seek times to find particular rows.

% We're not trying to define a universal bioinformatics file format,
% just to help people be more productive.
Wormtable is not intended to replace text files as the universal 
interchange format. It is intended to provide a persistent data structure 
that efficiently holds data in a form that can be efficiently processed 
and searched. Using this data structure, researchers with no knowledge of 
database systems can take full advantage of sophisticated 
data management techniques, and write simple code that processes this 
data in a very high performance manner. 
By providing conversion programs to convert 
common formats to wormtable, we also provide an easy to 
use common platform for 
bioinformatics analysis. This reduces the need for third party libraries 
to parse complex files and considerably simplifies the code required 
to process data.
Together, these advantages of increased performance and reduced 
code complexity can substantially increase a researcher's 
productivity and ability to explore their data.

% If we get some help, it could be pretty awesome...
Wormtable is an open and collaborative project seeking feedback and 
contributors. The project is in its early stages, currently 
providing a conversion tool for the VCF format only. With community
participation it may grow to support many other formats and become
a powerful common platform for bioinformatics data analysis.

\section*{Acknowledgement}
\paragraph{Funding\textcolon}  
JK is supported by EPSRC grant EP/I013091/1; DLH is supported by XXXXX; 
and RWN is supported by XXXX.

\bibliographystyle{plainnat}
\bibliography{paper}

\end{document}
